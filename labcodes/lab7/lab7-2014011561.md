# Lab 7 实验报告

#### 2014011561 张欣阳

> 注：为了在mac下编译，修改了Makefile文件，如果不能编译，请使用Makefile.bk

--------------------------------------------------------------------------------

## 练习0：更新以往lab
在lab7中，引入了计时器，在时钟中断产生时，调用`run_timer_list`从计时器队列里选择进程执行。在计时器机制下，替代了上个lab中直接在`trap_dispatch`中调用`sched_class_proc_tick`的实现。我们可以看到`run_timer_list`的实现如下：

```c
// call scheduler to update tick related info, and check the timer is expired? If expired, then wakup proc
void
run_timer_list(void) {
    bool intr_flag;
    local_intr_save(intr_flag);
    {
        list_entry_t *le = list_next(&timer_list);
        if (le != &timer_list) {
            timer_t *timer = le2timer(le, timer_link);
            assert(timer->expires != 0);
            timer->expires --;
            while (timer->expires == 0) {
                le = list_next(le);
                struct proc_struct *proc = timer->proc;
                if (proc->wait_state != 0) {
                    assert(proc->wait_state & WT_INTERRUPTED);
                }
                else {
                    warn("process %d's wait_state == 0.\n", proc->pid);
                }
                wakeup_proc(proc);
                del_timer(timer);
                if (le == &timer_list) {
                    break;
                }
                timer = le2timer(le, timer_link);
            }
        }
        sched_class_proc_tick(current);
    }
    local_intr_restore(intr_flag);
}
```
在这里面调用了`sched_class_proc_tick`来执行调度。

基于此，更改`trap_dispatch`中相关部分如下：
```c
case IRQ_OFFSET + IRQ_TIMER:
    ticks++;
    assert(current != NULL);
    run_timer_list();
    break;
```

## 练习1：理解内核级信号量的实现和基于内核级信号量的哲学家就餐问题
### 内核级信号量设计
ucore在sem.h中，定义了信号量的数据结构和函数：
```c
typedef struct {
    int value;
    wait_queue_t wait_queue;
} semaphore_t;

void sem_init(semaphore_t *sem, int value);
void up(semaphore_t *sem);
void down(semaphore_t *sem);
bool try_down(semaphore_t *sem);
```
信号量的结构体定义与其原理是对应的，包括资源量和一个进程等待队列。

`sem_init()`函数实现如下：
```c
void
sem_init(semaphore_t *sem, int value) {
    sem->value = value;
    wait_queue_init(&(sem->wait_queue));
}
```
实现非常简单，主要用来初始化信号量结构体，包括等待队列，以及资源的初始值；

`down`对应P操作，具体实现在`__down`函数中，其代码如下：
```c
static __noinline uint32_t __down(semaphore_t *sem, uint32_t wait_state) {
    bool intr_flag;
    local_intr_save(intr_flag);
    if (sem->value > 0) {
        sem->value --;
        local_intr_restore(intr_flag);
        return 0;
    }
    wait_t __wait, *wait = &__wait;
    wait_current_set(&(sem->wait_queue), wait, wait_state);
    local_intr_restore(intr_flag);

    schedule();

    local_intr_save(intr_flag);
    wait_current_del(&(sem->wait_queue), wait);
    local_intr_restore(intr_flag);

    if (wait->wakeup_flags != wait_state) {
        return wait->wakeup_flags;
    }
    return 0;
}

```
值得注意的是，该函数是通过关中断的方式来实现互斥访问的，过程与其原理完全对应：首先关掉中断，然后判断当前信号量的value是否大于0。如果是>0，则表明可以获得信号量，故让value减一，并打开中断返回即可；如果不是>0，则表明无法获得信号量，故需要将当前的进程加入到等待队列中，并打开中断，然后运行调度器选择另外一个进程执行。如果被V操作唤醒，则把自身关联的wait从等待队列中删除（此过程需要先关中断，完成后开中断）。
·
`up`对应V操作，具体是现在`__up`函数中，其代码如下：
```c
static __noinline void __up(semaphore_t *sem, uint32_t wait_state) {
    bool intr_flag;
    local_intr_save(intr_flag);
    {
        wait_t *wait;
        if ((wait = wait_queue_first(&(sem->wait_queue))) == NULL) {
            sem->value ++;
        }
        else {
            assert(wait->proc->wait_state == wait_state);
            wakeup_wait(&(sem->wait_queue), wait, wait_state, 1);
        }
    }
    local_intr_restore(intr_flag);
}
```
这个实现也与原理完全对应，首先关中断，如果信号量对应的wait queue中没有进程在等待，直接把信号量的value加一，然后开中断返回；如果有进程在等待且进程等待的原因是semophore设置的，则调用wakeup_wait函数将waitqueue中等待的第一个wait删除，且把此wait关联的进程唤醒，最后开中断返回。

这里还有一个函数`try_down`，它并没有被调用过，从实现上看好像是一个不包括等待队列的，不完全的`down`函数实现，可能用于调试。

值得注意的是，上一个lab中`mm_struct`中的`lock_t`也被`semaphore_t`代替了，通过信号量来表示进程的互斥锁。

ucore中，直接在`check_sync`函数中调用哲学家就餐代码，检查同步互斥实现，所以这部分代码在内核态运行。直接调用上面的信号量结构和函数就可以使用信号量了。

### 用户态信号量机制的设计方案
用户进程中，不能直接调用上面实现的信号量代码，因为这部分代码需要内核态的权限运行，但是我们仍然可以尝试复用这些代码。例如，我们可以编写用户态的库函数，复用`semaphore_t`结构体，但在调用`sem_init`，`up`和`down`时，通过系统调用的方式，增加三种系统调用；再在系统调用的实现中调用内核态的信号量代码，从而实现用户态的信号量机制。

## 练习2：完成内核级条件变量和基于内核级条件变量的哲学家就餐问题
### 内核级条件变量设计
条件变量定义在monitor.h中
```c
typedef struct condvar{
    semaphore_t sem;        // the sem semaphore  is used to down the waiting proc, and the signaling proc should up the waiting proc
    int count;              // the number of waiters on condvar
    monitor_t * owner;      // the owner(monitor) of this condvar
} condvar_t;
```
条件变量使用信号量实现，sem用于让发出wait_cv操作的等待某个条件为真的进程睡眠，而让发出signal_cv操作的进程通过这个sem来唤醒睡眠的进程。count表示等在这个条件变量上的睡眠进程的个数。owner表示此条件变量的宿主是哪个管程。

两个操作的实现分别如下，wait（LAB7练习2代码内容）：
```c
void
cond_wait (condvar_t *cvp) {
    //LAB7 EXERCISE1: 2014011561
    cprintf("cond_wait begin:  cvp %x, cvp->count %d, cvp->owner->next_count %d\n", cvp, cvp->count, cvp->owner->next_count);
    cvp->count++;
    if (cvp->owner->next_count > 0) {
        up(&(cvp->owner->next));
    } else {
        up(&(cvp->owner->mutex));
    }
    down(&(cvp->sem));
    cvp->count--;
    cprintf("cond_wait end:  cvp %x, cvp->count %d, cvp->owner->next_count %d\n", cvp, cvp->count, cvp->owner->next_count);
}
```
这里要注意由于条件变量是与管程配合使用的，所以实现的时候也是与管程紧密结合的。整体实现与其原理对应，不同的地方在于管程中`next`信号量的使用。这个信号量的作用如下，一个进程在执行管程signal操作后，我们规定采用Hoare策略，即采用signal的进程先等待，优先运行唤醒的进程。表示这个由于调用signal而等待的进程的信号量就是next。

signal实现如下（LAB7练习2代码内容）：
```c
void
cond_signal (condvar_t *cvp) {
    //LAB7 EXERCISE1: 2014011561
    cprintf("cond_signal begin: cvp %x, cvp->count %d, cvp->owner->next_count %d\n", cvp, cvp->count, cvp->owner->next_count);
    if (cvp->count > 0) {
        cvp->owner->next_count++;
        up(&(cvp->sem));
        down(&(cvp->owner->next));
        cvp->owner->next_count--;
    }
    cprintf("cond_signal end: cvp %x, cvp->count %d, cvp->owner->next_count %d\n", cvp, cvp->count, cvp->owner->next_count);
}
```
这里的实现同上面提到的思想一样，也是优先把其他等待进程唤醒，把本进程加入next队列，其他进程运行完后再运行本进程。

有了上面条件变量的实现，管程使用时要首先初始化条件变量；且调用在管程中保护的函数的调用的方式如下：
```
wait(mutex);
...
body of F
...

if (next count > 0)
    signal(next);
else
    signal(mutex);
```
其中F表示管程中的函数，在每个函数前后，要用mutex信号量加锁。F中则可以直接调用管程的。

### 用管程解决哲学家就餐问题
完整代码如下：
```c
struct proc_struct *philosopher_proc_condvar[N]; // N philosopher
int state_condvar[N];                            // the philosopher's state: EATING, HUNGARY, THINKING
monitor_t mt, *mtp=&mt;                          // monitor

void phi_test_condvar (i) {
    if(state_condvar[i]==HUNGRY&&state_condvar[LEFT]!=EATING
            &&state_condvar[RIGHT]!=EATING) {
        cprintf("phi_test_condvar: state_condvar[%d] will eating\n",i);
        state_condvar[i] = EATING ;
        cprintf("phi_test_condvar: signal self_cv[%d] \n",i);
        cond_signal(&mtp->cv[i]) ;
    }
}


void phi_take_forks_condvar(int i) {
     down(&(mtp->mutex));
//--------into routine in monitor--------------
    // LAB7 EXERCISE1: 2014011561
    // I am hungry
    // try to get fork
    state_condvar[i] = HUNGRY;
    phi_test_condvar(i);
    if (state_condvar[i] != EATING) {
        cond_wait(&(mtp->cv[i]));
    }
//--------leave routine in monitor--------------
      if(mtp->next_count>0)
         up(&(mtp->next));
      else
         up(&(mtp->mutex));
}

void phi_put_forks_condvar(int i) {
     down(&(mtp->mutex));

//--------into routine in monitor--------------
    // LAB7 EXERCISE1: 2014011561
    // I ate over
    // test left and right neighbors
    state_condvar[i] = THINKING;
    phi_test_condvar((i + 1) % 5);
    phi_test_condvar((i + 4) % 5);
//--------leave routine in monitor--------------
     if(mtp->next_count>0)
        up(&(mtp->next));
     else
        up(&(mtp->mutex));
}

//---------- philosophers using monitor (condition variable) ----------------------
int philosopher_using_condvar(void * arg) { /* arg is the No. of philosopher 0~N-1*/

    int i, iter=0;
    i=(int)arg;
    cprintf("I am No.%d philosopher_condvar\n",i);
    while(iter++<TIMES)
    { /* iterate*/
        cprintf("Iter %d, No.%d philosopher_condvar is thinking\n",iter,i); /* thinking*/
        do_sleep(SLEEP_TIME);
        phi_take_forks_condvar(i);
        /* need two forks, maybe blocked */
        cprintf("Iter %d, No.%d philosopher_condvar is eating\n",iter,i); /* eating*/
        do_sleep(SLEEP_TIME);
        phi_put_forks_condvar(i);
        /* return two forks back*/
    }
    cprintf("No.%d philosopher_condvar quit\n",i);
    return 0;
}
```
这个管程实现对应的资源是`state_condvar`，表示哲学家的状态，也反映了筷子使用的情况；条件变量是`mpt->cv`，一共有5个，表示每个哲学家是否能就餐。

其中，`phi_test_condvar`函数检查当前哲学家是否能就餐，如果能，则调用signal，同时把哲学家的状态改为正在就餐，也就表示着叉子资源被占用了；

`phi_take_forks_condvar`函数控制哲学家就餐，每次就餐前，需要调用test函数检查是否能就餐，如果不能，则应当wait，等待被唤醒；

`phi_put_forks_condvar`函数表示哲学家就餐完毕，应当把他的状态改成THINKING，同时调用test函数检查他两侧的哲学家，如果他们可以就餐，将会被signal唤醒。

### 用户态条件变量机制设计
同信号量的实现类似，由于我们现在的实现有了内核态才能运行的代码，所以不能直接搬到用户态。

在练习1中，我们已经给出了用户态信号量的实现方式，如果我们有了用户态的信号量，我们完全可以通过用户态信号量来实现用户态管程。具体的实现可以与我们在内核态用信号量实现管程的方式完全一致，只是把内核态信号量换成用户态信号量，即可实现用户态管程机制。

### 回答问题
> 能否不用基于信号量机制来完成条件变量？如果不能，请给出理由，如果能，请给出设计说明和具体实现。

可以不通过信号量实现管程。我们完全可以通过test-and-set原子操作直接实现，例如下面这个实现：

```c++
// Basic parts of threading system:
// Assume "ThreadQueue" supports random access.
public volatile ThreadQueue readyQueue; // Thread-unsafe queue of ready threads.  Elements are (Thread*).
public volatile global Thread* currentThread; // Assume this variable is per-core.  (Others are shared.)

// Implements a spin-lock on just the synchronized state of the threading system itself.
// This is used with test-and-set as the synchronization primitive.
public volatile global bool threadingSystemBusy=false;

// Context-switch interrupt service routine (ISR):
// On the current CPU core, preemptively switch to another thread.
public method contextSwitchISR(){
    if (testAndSet(threadingSystemBusy)){
        return; // Can't switch context right now.
    }

    // Ensure this interrupt can't happen again which would foul up the context switch:
    systemCall_disableInterrupts();

    // Get all of the registers of the currently-running process.
    // For Program Counter (PC), we will need the instruction location of
    // the "resume" label below.  Getting the register values is platform-dependent and may involve
    // reading the current stack frame, JMP/CALL instructions, etc.  (The details are beyond this scope.)
    currentThread->registers = getAllRegisters(); // Store the registers in the "currentThread" object in memory.
    currentThread->registers.PC = resume; // Set the next PC to the "resume" label below in this method.

    readyQueue.enqueue(currentThread); // Put this thread back onto the ready queue for later execution.

    Thread* otherThread=readyQueue.dequeue(); // Remove and get the next thread to run from the ready queue.

    currentThread=otherThread; // Replace the global current-thread pointer value so it is ready for the next thread.

    // Restore the registers from currentThread/otherThread, including a jump to the stored PC of the other thread
    // (at "resume" below).  Again, the details of how this is done are beyond this scope.
    restoreRegisters(otherThread.registers);

    // *** Now running "otherThread" (which is now "currentThread")!  The original thread is now "sleeping". ***

    resume: // This is where another contextSwitch() call needs to set PC to when switching context back here.

    // Return to where otherThread left off.

    threadingSystemBusy=false; // Must be an atomic assignment.
    systemCall_enableInterrupts(); // Turn pre-emptive switching back on on this core.

}

// Thread sleep method:
// On current CPU core, a synchronous context switch to another thread without putting
// the current thread on the ready queue.
// Must be holding "threadingSystemBusy" and disabled interrupts so that this method
// doesn't get interrupted by the thread-switching timer which would call contextSwitchISR().
// After returning from this method, must clear "threadingSystemBusy".
public method threadSleep(){
    // Get all of the registers of the currently-running process.
    // For Program Counter (PC), we will need the instruction location of
    // the "resume" label below.  Getting the register values is platform-dependent and may involve
    // reading the current stack frame, JMP/CALL instructions, etc.  (The details are beyond this scope.)
    currentThread->registers = getAllRegisters(); // Store the registers in the "currentThread" object in memory.
    currentThread->registers.PC = resume; // Set the next PC to the "resume" label below in this method.

    // Unlike contextSwitchISR(), we will not place currentThread back into readyQueue.
    // Instead, it has already been placed onto a mutex's or condition variable's queue.

    Thread* otherThread=readyQueue.dequeue(); // Remove and get the next thread to run from the ready queue.

    currentThread=otherThread; // Replace the global current-thread pointer value so it is ready for the next thread.

    // Restore the registers from currentThread/otherThread, including a jump to the stored PC of the other thread
    // (at "resume" below).  Again, the details of how this is done are beyond this scope.
    restoreRegisters(otherThread.registers);

    // *** Now running "otherThread" (which is now "currentThread")!  The original thread is now "sleeping". ***

    resume: // This is where another contextSwitch() call needs to set PC to when switching context back here.

    // Return to where otherThread left off.

}

public method wait(Mutex m, ConditionVariable c){
    // Internal spin-lock while other threads on any core are accessing this object's
    // "held" and "threadQueue", or "readyQueue".
    while (testAndSet(threadingSystemBusy)){}
    // N.B.: "threadingSystemBusy" is now true.

    // System call to disable interrupts on this core so that threadSleep() doesn't get interrupted by
    // the thread-switching timer on this core which would call contextSwitchISR().
    // Done outside threadSleep() for more efficiency so that this thread will be sleeped
    // right after going on the condition-variable queue.
    systemCall_disableInterrupts();

    assert m.held; // (Specifically, this thread must be the one holding it.)

    m.release();
    c.waitingThreads.enqueue(currentThread);

    threadSleep();

    // Thread sleeps ... Thread gets woken up from a signal/broadcast.

    threadingSystemBusy=false; // Must be an atomic assignment.
    systemCall_enableInterrupts(); // Turn pre-emptive switching back on on this core.

    // Mesa style:
    // Context switches may now occur here, making the client caller's predicate false.

    m.acquire();

}

public method signal(ConditionVariable c){

    // Internal spin-lock while other threads on any core are accessing this object's
    // "held" and "threadQueue", or "readyQueue".
    while (testAndSet(threadingSystemBusy)){}
    // N.B.: "threadingSystemBusy" is now true.

    // System call to disable interrupts on this core so that threadSleep() doesn't get interrupted by
    // the thread-switching timer on this core which would call contextSwitchISR().
    // Done outside threadSleep() for more efficiency so that this thread will be sleeped
    // right after going on the condition-variable queue.
    systemCall_disableInterrupts();

    if (!c.waitingThreads.isEmpty()){
        wokenThread=c.waitingThreads.dequeue();
        readyQueue.enqueue(wokenThread);
    }

    threadingSystemBusy=false; // Must be an atomic assignment.
    systemCall_enableInterrupts(); // Turn pre-emptive switching back on on this core.

    // Mesa style:
    // The woken thread is not given any priority.

}

public method broadcast(ConditionVariable c){

    // Internal spin-lock while other threads on any core are accessing this object's
    // "held" and "threadQueue", or "readyQueue".
    while (testAndSet(threadingSystemBusy)){}
    // N.B.: "threadingSystemBusy" is now true.

    // System call to disable interrupts on this core so that threadSleep() doesn't get interrupted by
    // the thread-switching timer on this core which would call contextSwitchISR().
    // Done outside threadSleep() for more efficiency so that this thread will be sleeped
    // right after going on the condition-variable queue.
    systemCall_disableInterrupts();

    while (!c.waitingThreads.isEmpty()){
        wokenThread=c.waitingThreads.dequeue();
        readyQueue.enqueue(wokenThread);
    }

    threadingSystemBusy=false; // Must be an atomic assignment.
    systemCall_enableInterrupts(); // Turn pre-emptive switching back on on this core.

    // Mesa style:
    // The woken threads are not given any priority.

}

class Mutex {
    protected volatile bool held=false;
    private volatile ThreadQueue blockingThreads; // Thread-unsafe queue of blocked threads.  Elements are (Thread*).

    public method acquire(){
        // Internal spin-lock while other threads on any core are accessing this object's
        // "held" and "threadQueue", or "readyQueue".
        while (testAndSet(threadingSystemBusy)){}
        // N.B.: "threadingSystemBusy" is now true.

        // System call to disable interrupts on this core so that threadSleep() doesn't get interrupted by
        // the thread-switching timer on this core which would call contextSwitchISR().
        // Done outside threadSleep() for more efficiency so that this thread will be sleeped
        // right after going on the lock queue.
        systemCall_disableInterrupts();

        assert !blockingThreads.contains(currentThread);

        if (held){
            // Put "currentThread" on this lock's queue so that it will be
            // considered "sleeping" on this lock.
            // Note that "currentThread" still needs to be handled by threadSleep().
            readyQueue.remove(currentThread);
            blockingThreads.enqueue(currentThread);
            threadSleep();

            // Now we are woken up, which must be because "held" became false.
            assert !held;
            assert !blockingThreads.contains(currentThread);
        }

        held=true;

        threadingSystemBusy=false; // Must be an atomic assignment.
        systemCall_enableInterrupts(); // Turn pre-emptive switching back on on this core.

    }

    public method release(){
        // Internal spin-lock while other threads on any core are accessing this object's
        // "held" and "threadQueue", or "readyQueue".
        while (testAndSet(threadingSystemBusy)){}
        // N.B.: "threadingSystemBusy" is now true.

        // System call to disable interrupts on this core for efficiency.
        systemCall_disableInterrupts();

        assert held; // (Release should only be performed while the lock is held.)

        held=false;

        if (!blockingThreads.isEmpty()){
            Thread* unblockedThread=blockingThreads.dequeue();
            readyQueue.enqueue(unblockedThread);
        }

        threadingSystemBusy=false; // Must be an atomic assignment.
        systemCall_enableInterrupts(); // Turn pre-emptive switching back on on this core.

    }

}

struct ConditionVariable {

    volatile ThreadQueue waitingThreads;

}
```

## 与参考答案差别

与参考答案基本一致

## 实验中重要的知识点
- 信号量原理
- Hoare 管程原理：注意为实现进程 signal 时唤醒等待该条件变量的进程，之后又恢复执行，需要增加`next`，使得执行流程和复杂度增加
- 用信号量和管程解决哲学家就餐问题

## 实验未覆盖知识点

- Hansen 管程的实现方法，相比较 Hoare 而言只需去掉所有 `next` 相关实现，相对简单一些
